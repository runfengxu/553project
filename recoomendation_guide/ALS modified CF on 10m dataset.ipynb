{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import *\n",
    "import numpy as np\n",
    "from itertools import permutations\n",
    "from pyspark.mllib.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_ratings_raw_data = sc.textFile('/Users/gregcattell/PyProjects/data/PJ_data/ml-10M100K/ratings.csv')\n",
    "\n",
    "small_ratings_data = small_ratings_raw_data.map(lambda line : line.split(\"::\")).map(lambda tokens: (tokens[0],tokens[1],tokens[2]))\\\n",
    ".map(lambda x: (int(x[0]), int(x[1]), float(x[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_movies_raw_data = sc.textFile('/Users/gregcattell/PyProjects/data/PJ_data/ml-10M100K/movies.csv')\n",
    "\n",
    "small_movies_data = small_movies_raw_data.map(lambda line: line.split(\",\")).map(lambda tokens: tokens[0])\\\n",
    ".map(lambda line: line.split(\"::\")).map(lambda x: (int(x[0]), x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 122, 5.0), (1, 185, 5.0), (1, 231, 5.0)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_ratings_data.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Toy Story (1995)'),\n",
       " (2, 'Jumanji (1995)'),\n",
       " (3, 'Grumpier Old Men (1995)')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_movies_data.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train_RDD, pre_valid_RDD, pre_test_RDD = small_ratings_data.randomSplit([6, 2, 2], seed=0)\n",
    "validation_for_predict_RDD = pre_valid_RDD.map(lambda x: (x[0], x[1]))\n",
    "test_for_predict_RDD = pre_test_RDD.map(lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 4 the MAE is:  0.6477914583162161 the RMSE is:  0.8305049650186825\n",
      "For rank 8 the MAE is:  0.639625696720242 the RMSE is:  0.819310378075049\n",
      "For rank 12 the MAE is:  0.6364687838721681 the RMSE is:  0.8153714189001765\n",
      "The best model was trained with rank:  12\n"
     ]
    }
   ],
   "source": [
    "seed = 5\n",
    "iterations = 10\n",
    "regularization_parameter = 0.1\n",
    "ranks = [4, 8, 12]\n",
    "errors = [0, 0, 0]\n",
    "err = 0\n",
    "tolerance = 0.02\n",
    "\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "best_iteration = -1\n",
    "for rank in ranks:\n",
    "    model = ALS.train(pre_train_RDD, rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularization_parameter)\n",
    "    predictions = model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    rates_and_preds = pre_valid_RDD.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "    MAE = rates_and_preds.map(lambda r: abs(r[1][0] - r[1][1])).mean()\n",
    "    RMSE = np.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    errors[err] = RMSE\n",
    "    err += 1\n",
    "    print('For rank', rank,'the MAE is: ', MAE,'the RMSE is: ', RMSE) \n",
    "    if RMSE < min_error:\n",
    "        min_error = RMSE\n",
    "        best_rank = rank\n",
    "\n",
    "print('The best model was trained with rank: ', best_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_RDD, test_RDD = small_ratings_data.randomSplit([8, 2], seed=0)\n",
    "test_user_unwatch = test_RDD.map(lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the MAR is 0.6349936503753815\n",
      "For testing data the RMSE is 0.8125630451607231\n"
     ]
    }
   ],
   "source": [
    "model = ALS.train(training_RDD, best_rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularization_parameter)\n",
    "predictions = model.predictAll(test_user_unwatch).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_preds = test_RDD.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "MAE = rates_and_preds.map(lambda r: abs(r[1][0] - r[1][1])).mean()\n",
    "RMSE = np.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "\n",
    "print('For testing data the MAR is', MAE)\n",
    "print('For testing data the RMSE is', RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prediction for one user = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 2\n",
    "movie_set = small_movies_data.map(lambda x: x[0])\n",
    "u_w_new = training_RDD.filter(lambda x: x[0] == index).map(lambda x: x[1])\n",
    "u_u_new = movie_set.subtract(u_w_new).map(lambda x: (index, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 10), (2, 20), (2, 30)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_u_new.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_prediction = model.predictAll(u_u_new).map(lambda r: ((r[0], r[1]), r[2]))\\\n",
    ".map(lambda x: (x[0][0], (x[0][1], x[1])))\\\n",
    ".top(10, key = lambda x: x[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top_Ten = sc.parallelize(u_prediction).map(lambda x: (x[0], x[1][0]))\\\n",
    ".groupByKey().map(lambda x: (x[0], list(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlist = test_RDD.map(lambda r: (r[0], (r[1], r[2]))).filter(lambda r: r[0] == index)\\\n",
    ".sortBy(lambda x: x[1][1], ascending = False).map(lambda x: (x[0], x[1][0])).groupByKey()\\\n",
    ".map(lambda line: (line[0], list(line[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = testlist.map(lambda r: (r[0], set(r[1])))\n",
    "recom = Top_Ten.map(lambda r: (r[0], set(r[1])))\n",
    "\n",
    "comparison_com = true.join(recom)\\\n",
    ".map(lambda x: (len(x[1][0] & x[1][1]), len(x[1][1]),len(x[1][0])))\\\n",
    ".map(lambda x: (x[0]/x[1], x[0]/x[2])).collect()\n",
    "\n",
    "F_measure = 2 * precision *recall/ (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision for 2 0.1\n",
      "recall for 2 0.16666666666666666\n",
      "F_measure: 2 0.7376004004114871\n"
     ]
    }
   ],
   "source": [
    "print(\"precision for\", index, comparison_com[0][0])\n",
    "print(\"recall for\", index, comparison_com[0][1])\n",
    "print(\"F_measure:\", index, F_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nDCG(test, prediction):\n",
    "    DCG =0\n",
    "    IDCG = 0\n",
    "    j=1\n",
    "    for i in range(len(test)):\n",
    "        if test[i] in prediction:\n",
    "            DCG+=1/np.log2(1+i+1)\n",
    "            IDCG+=1/np.log2(j+1)\n",
    "            j+=1\n",
    "    if IDCG!=0:\n",
    "        return DCG/IDCG\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = testlist.flatMap(lambda r: r[1]).collect()\n",
    "predic = Top_Ten.flatMap(lambda r: r[1]).collect()\n",
    "comparison_ndcg = nDCG(test, predic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2tuple(u, line):\n",
    "    tup = [(x, u) for x in line]\n",
    "    return tup\n",
    "trueMList = testlist.flatMap(lambda x: l2tuple(x[0], x[1]))\n",
    "predMList = Top_Ten.flatMap(lambda x: l2tuple(x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "TM = trueMList.join(small_movies_data).map(lambda x: (x[1][0], x[0], x[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 110, 'Braveheart (1995)'),\n",
       " (2, 590, 'Dances with Wolves (1990)'),\n",
       " (2, 1210, 'Star Wars: Episode VI - Return of the Jedi (1983)'),\n",
       " (2, 802, 'Phenomenon (1996)'),\n",
       " (2, 736, 'Twister (1996)'),\n",
       " (2, 1356, 'Star Trek: First Contact (1996)')]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TM.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "PM = predMList.join(small_movies_data).map(lambda x: (x[1][0], x[0], x[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 8120, '29th Street (1991)'),\n",
       " (2, 65133, 'Blackadder Back & Forth (1999)'),\n",
       " (2, 25975, 'Life of Oharu'),\n",
       " (2, 1196, 'Star Wars: Episode V - The Empire Strikes Back (1980)'),\n",
       " (2, 1210, 'Star Wars: Episode VI - Return of the Jedi (1983)'),\n",
       " (2,\n",
       "  1198,\n",
       "  'Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)'),\n",
       " (2, 32657, 'Man Who Planted Trees'),\n",
       " (2, 1787, 'Paralyzing Fear: The Story of Polio in America'),\n",
       " (2, 4993, 'Lord of the Rings: The Fellowship of the Ring'),\n",
       " (2, 7153, 'Lord of the Rings: The Return of the King')]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PM.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nDCG(test, prediction):\n",
    "    DCG =0\n",
    "    IDCG = 0\n",
    "    j=1\n",
    "    for p in range(len(test)):\n",
    "        if test[p] in prediction:\n",
    "            DCG+=1/np.log2(1+p+1)\n",
    "            IDCG+=1/np.log2(j+1)\n",
    "            j+=1\n",
    "    if IDCG!=0:\n",
    "        return DCG/IDCG\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision for 1 0.0\n",
      "recall for 1 0.0\n",
      "precision for 2 0.1\n",
      "recall for 2 0.16666666666666666\n",
      "precision for 3 0.0\n",
      "recall for 3 0.0\n",
      "precision for 4 0.0\n",
      "recall for 4 0.0\n",
      "precision for 5 0.0\n",
      "recall for 5 0.0\n",
      "precision for 6 0.0\n",
      "recall for 6 0.0\n",
      "precision for 7 0.0\n",
      "recall for 7 0.0\n",
      "precision for 8 0.0\n",
      "recall for 8 0.0\n",
      "precision for 9 0.0\n",
      "recall for 9 0.0\n",
      "precision for 10 0.0\n",
      "recall for 10 0.0\n",
      "precision for 11 0.0\n",
      "recall for 11 0.0\n",
      "precision for 12 0.0\n",
      "recall for 12 0.0\n",
      "precision for 13 0.0\n",
      "recall for 13 0.0\n",
      "precision for 14 0.0\n",
      "recall for 14 0.0\n",
      "precision for 16 0.0\n",
      "recall for 16 0.0\n",
      "precision for 17 0.0\n",
      "recall for 17 0.0\n",
      "precision for 18 0.0\n",
      "recall for 18 0.0\n",
      "precision for 19 0.0\n",
      "recall for 19 0.0\n",
      "precision for 22 0.0\n",
      "recall for 22 0.0\n",
      "precision for 23 0.0\n",
      "recall for 23 0.0\n",
      "precision for 24 0.0\n",
      "recall for 24 0.0\n",
      "precision for 26 0.0\n",
      "recall for 26 0.0\n",
      "precision for 27 0.0\n",
      "recall for 27 0.0\n",
      "precision for 28 0.0\n",
      "recall for 28 0.0\n",
      "precision for 29 0.0\n",
      "recall for 29 0.0\n",
      "precision for 30 0.0\n",
      "recall for 30 0.0\n",
      "precision for 33 0.0\n",
      "recall for 33 0.0\n",
      "precision for 34 0.1\n",
      "recall for 34 0.00684931506849315\n",
      "precision for 35 0.0\n",
      "recall for 35 0.0\n",
      "precision for 36 0.0\n",
      "recall for 36 0.0\n",
      "precision for 37 0.0\n",
      "recall for 37 0.0\n",
      "precision for 38 0.0\n",
      "recall for 38 0.0\n",
      "precision for 40 0.0\n",
      "recall for 40 0.0\n",
      "precision for 41 0.0\n",
      "recall for 41 0.0\n",
      "precision for 42 0.0\n",
      "recall for 42 0.0\n",
      "precision for 43 0.0\n",
      "recall for 43 0.0\n",
      "precision for 44 0.0\n",
      "recall for 44 0.0\n",
      "precision for 45 0.1\n",
      "recall for 45 0.047619047619047616\n",
      "precision for 46 0.0\n",
      "recall for 46 0.0\n",
      "precision for 47 0.0\n",
      "recall for 47 0.0\n",
      "precision for 48 0.0\n",
      "recall for 48 0.0\n",
      "precision for 50 0.1\n",
      "recall for 50 0.14285714285714285\n",
      "precision for 51 0.0\n",
      "recall for 51 0.0\n",
      "precision for 52 0.0\n",
      "recall for 52 0.0\n",
      "precision for 53 0.0\n",
      "recall for 53 0.0\n",
      "precision for 54 0.1\n",
      "recall for 54 0.0625\n",
      "precision for 55 0.0\n",
      "recall for 55 0.0\n",
      "precision for 56 0.0\n",
      "recall for 56 0.0\n",
      "precision for 57 0.0\n",
      "recall for 57 0.0\n",
      "precision for 58 0.0\n",
      "recall for 58 0.0\n",
      "precision for 59 0.0\n",
      "recall for 59 0.0\n",
      "precision for 60 0.0\n",
      "recall for 60 0.0\n",
      "precision for 61 0.0\n",
      "recall for 61 0.0\n",
      "precision for 62 0.0\n",
      "recall for 62 0.0\n",
      "precision for 63 0.0\n",
      "recall for 63 0.0\n",
      "precision for 64 0.0\n",
      "recall for 64 0.0\n",
      "precision for 65 0.0\n",
      "recall for 65 0.0\n",
      "precision for 66 0.0\n",
      "recall for 66 0.0\n",
      "precision for 67 0.0\n",
      "recall for 67 0.0\n",
      "precision for 68 0.0\n",
      "recall for 68 0.0\n",
      "precision for 69 0.0\n",
      "recall for 69 0.0\n",
      "precision for 70 0.0\n",
      "recall for 70 0.0\n",
      "precision for 71 0.0\n",
      "recall for 71 0.0\n",
      "precision for 72 0.0\n",
      "recall for 72 0.0\n",
      "precision for 73 0.0\n",
      "recall for 73 0.0\n",
      "precision for 74 0.0\n",
      "recall for 74 0.0\n",
      "precision for 75 0.0\n",
      "recall for 75 0.0\n",
      "precision for 76 0.0\n",
      "recall for 76 0.0\n",
      "precision for 77 0.0\n",
      "recall for 77 0.0\n",
      "precision for 78 0.0\n",
      "recall for 78 0.0\n",
      "precision for 79 0.0\n",
      "recall for 79 0.0\n",
      "precision for 80 0.1\n",
      "recall for 80 0.2\n",
      "precision for 81 0.0\n",
      "recall for 81 0.0\n",
      "precision for 82 0.0\n",
      "recall for 82 0.0\n",
      "precision for 83 0.0\n",
      "recall for 83 0.0\n",
      "precision for 84 0.0\n",
      "recall for 84 0.0\n",
      "precision for 85 0.0\n",
      "recall for 85 0.0\n",
      "precision for 86 0.0\n",
      "recall for 86 0.0\n",
      "precision for 87 0.0\n",
      "recall for 87 0.0\n",
      "precision for 88 0.0\n",
      "recall for 88 0.0\n",
      "precision for 89 0.0\n",
      "recall for 89 0.0\n",
      "precision for 90 0.0\n",
      "recall for 90 0.0\n",
      "precision for 91 0.0\n",
      "recall for 91 0.0\n",
      "precision for 92 0.1\n",
      "recall for 92 0.034482758620689655\n",
      "precision for 93 0.0\n",
      "recall for 93 0.0\n",
      "precision for 94 0.0\n",
      "recall for 94 0.0\n",
      "precision for 95 0.0\n",
      "recall for 95 0.0\n",
      "precision for 96 0.0\n",
      "recall for 96 0.0\n",
      "precision for 97 0.0\n",
      "recall for 97 0.0\n",
      "precision for 98 0.0\n",
      "recall for 98 0.0\n",
      "precision for 99 0.0\n",
      "recall for 99 0.0\n",
      "precision for 100 0.1\n",
      "recall for 100 0.023255813953488372\n"
     ]
    }
   ],
   "source": [
    "precision = 0\n",
    "recall = 0\n",
    "comparison_ndcg = 0\n",
    "iterations = 100\n",
    "\n",
    "for i in range(iterations):\n",
    "    index = i+1\n",
    "    movie_set = small_movies_data.map(lambda x: x[0])\n",
    "    u_w_new = training_RDD.filter(lambda x: x[0] == index).map(lambda x: x[1])\n",
    "    u_u_new = movie_set.subtract(u_w_new).map(lambda x: (index, x))\n",
    "\n",
    "    u_prediction = model.predictAll(u_u_new).map(lambda r: ((r[0], r[1]), r[2]))\\\n",
    "    .map(lambda x: (x[0][0], (x[0][1], x[1])))\\\n",
    "    .top(10, key = lambda x: x[1][1])\n",
    "\n",
    "    Top_Ten = sc.parallelize(u_prediction).map(lambda x: (x[0], x[1][0]))\\\n",
    "    .groupByKey().map(lambda x: (x[0], list(x[1])))\n",
    "\n",
    "    testlist = test_RDD.map(lambda r: (r[0], (r[1], r[2]))).filter(lambda r: r[0] == index)\\\n",
    "    .sortBy(lambda x: x[1][1], ascending = False).map(lambda x: (x[0], x[1][0])).groupByKey()\\\n",
    "    .map(lambda line: (line[0], list(line[1])))\n",
    "\n",
    "    true = testlist.map(lambda r: (r[0], set(r[1])))\n",
    "    recom = Top_Ten.map(lambda r: (r[0], set(r[1])))\n",
    "\n",
    "    comparison_com = true.join(recom)\\\n",
    "    .map(lambda x: (len(x[1][0] & x[1][1]), len(x[1][1]),len(x[1][0])))\\\n",
    "    .map(lambda x: (x[0]/x[1], x[0]/x[2])).collect()\n",
    "    \n",
    "    if len(comparison_com)==0:\n",
    "        continue\n",
    "    if len(comparison_com)!=0:\n",
    "        precision +=comparison_com[0][0]\n",
    "        recall +=comparison_com[0][1]\n",
    " \n",
    "    print(\"precision for\", i+1, comparison_com[0][0])\n",
    "    print(\"recall for\", i+1, comparison_com[0][1])\n",
    "\n",
    "    test = testlist.flatMap(lambda r: r[1]).collect()\n",
    "    predic = Top_Ten.flatMap(lambda r: r[1]).collect()\n",
    "    comparison_ndcg += nDCG(test, predic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_mean = precision/iterations\n",
    "recall_mean = recall/iterations\n",
    "F_measure = 2 * precision *recall/ (precision + recall)\n",
    "ndcg_mean = comparison_ndcg/iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.008\n",
      "recall:  0.006842307447855284\n",
      "F-measure:  0.7376004004114871\n",
      "nDCG:  0.04293432703646809\n"
     ]
    }
   ],
   "source": [
    "print(\"precision: \", precision_mean)\n",
    "print(\"recall: \", recall_mean)\n",
    "print(\"F-measure: \", F_measure)\n",
    "print(\"nDCG: \", ndcg_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
