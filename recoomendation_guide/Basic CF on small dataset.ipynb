{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import *\n",
    "import numpy as np\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_ratings_raw_data = sc.textFile('/Users/gregcattell/PyProjects/data/PJ_data/ml-latest-small/ratings.csv')\n",
    "small_ratings_raw_data_header = small_ratings_raw_data.take(1)[0]\n",
    "\n",
    "small_ratings_data = small_ratings_raw_data.filter(lambda line: line!=small_ratings_raw_data_header)\\\n",
    ".map(lambda line : line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1],tokens[2]))\\\n",
    ".map(lambda x: (int(x[0]), int(x[1]), float(x[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_movies_raw_data = sc.textFile('/Users/gregcattell/PyProjects/data/PJ_data/ml-latest-small/movies.csv')\n",
    "small_movies_raw_data_header = small_movies_raw_data.take(1)[0]\n",
    "\n",
    "small_movies_data = small_movies_raw_data.filter(lambda line: line!=small_movies_raw_data_header)\\\n",
    ".map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1]))\\\n",
    ".map(lambda x: (int(x[0]), x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ______Checking data set: \n",
    "#### small_ratings_data = (userID, movieID, rating)\n",
    "#### small_movies_data = (movieID, movieName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1, 4.0), (1, 3, 4.0), (1, 6, 4.0)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_ratings_data.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Toy Story (1995)'),\n",
       " (2, 'Jumanji (1995)'),\n",
       " (3, 'Grumpier Old Men (1995)')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_movies_data.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training set and test set: 8:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_RDD, test_RDD = small_ratings_data.randomSplit([8, 2], seed=0)\n",
    "test_user_unwatch = test_RDD.map(lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ___Checking data set:\n",
    "#### Numbers of training data and test data\n",
    "#### test samples for prediction: (userID, unWatchedID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of training dataset is 80720\n",
      "The total number of test dataset is 20116\n",
      "Rate of training and test: 4.012726188108968\n"
     ]
    }
   ],
   "source": [
    "Total_train = training_RDD.count()\n",
    "Total_test = test_RDD.count()\n",
    "print(\"The total number of training dataset is\", Total_train)\n",
    "print(\"The total number of test dataset is\", Total_test)\n",
    "print(\"Rate of training and test:\", Total_train/Total_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 70), (1, 101), (1, 110)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_user_unwatch.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the rating of movie: subtract mean rating $m_{i}$ from each movie i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_means = training_RDD.map(lambda x: (x[1], (x[2], 1))).reduceByKey(lambda x, y: (x[0]+y[0], x[1]+y[1]))\\\n",
    ".map(lambda x: (x[0], x[1][0]/x[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_ratings = training_RDD.map(lambda x: (x[1], (x[0], x[2]))).join(movie_means)\\\n",
    ".map(lambda x: (x[1][0][0], x[0], x[1][0][1] - x[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ___Checking dataset:\n",
    "#### movie_means: (movie, mean of ratings)\n",
    "#### normalized_ratings: (userID, movieID, norm_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6, 3.98125), (50, 4.2398843930635834), (260, 4.21875)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_means.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 260, 0.78125), (4, 260, 0.78125), (7, 260, 0.78125)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_ratings.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting cosine similarity with Pearson correlation coefficient\n",
    "### $S_{xy} = $ items rated by both user x and user y\n",
    "### $m_{1}$ and $m_{2}$ are normalized movie ratings\n",
    "\n",
    "<font size = \"5\">\n",
    "\n",
    "$$\n",
    "sim =  \\frac{\\sum_{s \\in S_{xy} } m_{1} \\times m_{2}}{ \\sqrt{\\sum_{s \\in S_{xy} } m_{1}^{2}} \\sqrt{\\sum_{s \\in S_{xy} } m_{2}^{2}} }\n",
    "$$\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_perm(line):\n",
    "    perm = list(permutations(line, 2))\n",
    "    return perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(user, list((movie, ratings)))\n",
    "#((m1, r1), (m2, r2))\n",
    "#((m1, m2),(r1*r2, r1^2, r2^2))\n",
    "#((m1, m2), (sum(r1*r2), sum(r1^2), sum(r2^2)))\n",
    "#((m1,m2), sim)\n",
    "\n",
    "cosine_sim = normalized_ratings.map(lambda x: (x[0], (x[1], x[2]))).groupByKey()\\\n",
    ".flatMap(lambda x: item_perm(list(x[1])))\\\n",
    ".map(lambda x: ((x[0][0], x[1][0]),(x[0][1]*x[1][1], x[0][1]**2, x[1][1]**2)))\\\n",
    ".reduceByKey(lambda x, y: (x[0]+y[0], x[1]+y[1], x[2]+y[2]))\\\n",
    ".map(lambda x: (x[0], x[1][0]/ np.sqrt(x[1][1]) / np.sqrt(x[1][2])) if (x[1][1] * x[1][2])!= 0 else \\\n",
    "    (x[0],0)).cache() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ____Checking dataset:\n",
    "#### cosine_sim: (movie_1, movie_2, similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1240, 61350), 0.999314833766767),\n",
       " ((2028, 1358), -0.1775294625417523),\n",
       " ((5632, 33794), -0.9515851669023498)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting baseline estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = training_RDD.map(lambda x: x[2]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx = training_RDD.map(lambda x: (x[0], (x[2], 1))).reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\\\n",
    ".map(lambda x: (x[0], x[1][0]/x[1][1] - mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi = movie_means.map(lambda x: (x[0], x[1] - mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx_dict = {x[0]: x[1] for x in bx.collect()}\n",
    "bi_dict = {x[0]: x[1] for x in bi.collect()}\n",
    "\n",
    "def baseLine(user, movie):\n",
    "    if movie not in bi_dict:\n",
    "        return bx_dict[user] + mu\n",
    "    return bx_dict[user] + bi_dict[movie] + mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ___checking dataset:\n",
    "#### mu, bx(user, bx), bi(movie, bi)\n",
    "#### baseLine(user, movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.502682111000975"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6, 0.478567888999025), (50, 0.7372022820626083), (260, 0.7160678889990248)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.41398455566569137),\n",
       " (4, 0.02141427454119338),\n",
       " (6, -0.024579921219953338)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.3952345556656915"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseLine(2,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the estimate rating rxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_RDD.map(lambda x: (x[1], x[0])) #(unwatched, uId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_sim = cosine_sim.map(lambda x: (x[0][0],(x[0][1], x[1]))) #(unwatched, (watched, sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_rating = training_RDD.map(lambda x: ((x[0], x[1]), x[2])) #((user, watched), rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We choose the top four nearest neighbors for each (user, unwatched) pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "uu_wrs = movie_sim.join(test_data)\\\n",
    ".map(lambda x: ((x[1][1], x[1][0][0]), (x[0], x[1][0][1])))\\\n",
    ".join(training_rating).map(lambda x: ((x[0][0], x[1][0][0]),(x[0][1], x[1][1], x[1][0][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rxi(uu, wrs, k):\n",
    "    user, unwat = uu\n",
    "    wrs.sort(key = lambda x: x[2], reverse = True)\n",
    "    numerator =0 \n",
    "    denominator =0\n",
    "    for wrs_unit in wrs[:k]:\n",
    "        wat, rat, sim = wrs_unit\n",
    "        numerator += sim * (rat - baseLine(user, wat))\n",
    "        denominator += sim\n",
    "    if denominator ==0:\n",
    "        return (uu, baseLine(user,unwat))\n",
    "    return (uu, baseLine(user, unwat)+numerator/denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=7\n",
    "prediction = uu_wrs.groupByKey().map(lambda x: rxi(x[0], list(x[1]), k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ___checking dataset:\n",
    "#### uu_wrs: ((user, watched), (unwatched, rating, sim))\n",
    "#### rxi function:\n",
    "#### prediction: ((user, unwatched), rxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((414, 91542), (420, 2.0, 0.7437188876603105)),\n",
       " ((414, 6942), (420, 2.0, 0.38952960301417106)),\n",
       " ((414, 1320), (420, 2.0, 0.3004950270825381))]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uu_wrs.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 3), 2.896390178144837)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uu = (1,3)\n",
    "wrs = [(1, 2.0, 0.45), (5, 4.0, 0.6), (12, 3.5, 0.2), (14, 2.5, 0.36)]\n",
    "k = 4\n",
    "rij(uu, wrs, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((600, 750), 4.059201090074584),\n",
       " ((600, 38886), 3.1030505952380953),\n",
       " ((600, 8910), 2.869765866873065)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with the true value, calculating MSE & RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_value = test_RDD.map(lambda x: ((x[0], x[1]), x[2]))\n",
    "comparison = prediction.join(test_value).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((600, 1270), (4.0629975124378115, 4.5)),\n",
       " ((600, 2302), (3.265292553191489, 3.0)),\n",
       " ((182, 1644), (2.0463721804511277, 3.5))]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE = comparison.map(lambda x: abs(x[1][0] - x[1][1])).mean()\n",
    "RMSE = np.sqrt(comparison.map(lambda x: (x[1][0]-x[1][1])**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE for the CF prediction is:  0.7491815388690404\n",
      "The RMSE for the CF prediction is:  0.9776822718371895\n"
     ]
    }
   ],
   "source": [
    "print(\"The MAE for the CF prediction is: \", MAE)\n",
    "print(\"The RMSE for the CF prediction is: \", RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### However, there are some missing data, we can check the volume of comparision and test_RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    }
   ],
   "source": [
    "missing_data = test_RDD.count() - comparison.count()\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is because some movies in test set are not in training set\n",
    "### So, some movie information are not in similarity table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_movie_train = training_RDD.map(lambda x: (x[1])).distinct().count()\n",
    "num_movie = small_movies_data.count()\n",
    "missing_movie = num_movie - num_movie_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_uu = prediction.map(lambda x: x[0])\n",
    "mis_part = test_RDD.map(lambda x: (x[0], x[1])).subtract(pred_uu)\\\n",
    ".map(lambda x: ((x[0],x[1]), baseLine(x[0], x[1])))\n",
    "pred_Total = prediction.union(mis_part)\n",
    "comp_Total = pred_Total.join(test_value).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE_T = comp_Total.map(lambda x: abs(x[1][0] - x[1][1])).mean()\n",
    "RMSE_T = np.sqrt(comp_Total.map(lambda x: (x[1][0]-x[1][1])**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE for the CF prediction is:  0.7506121072803289\n",
      "The RMSE for the CF prediction is:  0.9796308461005092\n"
     ]
    }
   ],
   "source": [
    "print(\"The MAE for the CF prediction is: \", MAE_T)\n",
    "print(\"The RMSE for the CF prediction is: \", RMSE_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ALS for recommendation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train_RDD, pre_valid_RDD, pre_test_RDD = small_ratings_data.randomSplit([6, 2, 2], seed=0)\n",
    "validation_for_predict_RDD = pre_valid_RDD.map(lambda x: (x[0], x[1]))\n",
    "test_for_predict_RDD = pre_test_RDD.map(lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 4 the MAE is:  0.6984923736604529 the RMSE is:  0.9114026007220244\n",
      "For rank 8 the MAE is:  0.7045145440395727 the RMSE is:  0.9180911451666388\n",
      "For rank 12 the MAE is:  0.7087779592332236 the RMSE is:  0.9183376003842972\n",
      "The best model was trained with rank:  4\n"
     ]
    }
   ],
   "source": [
    "seed = 5\n",
    "iterations = 10\n",
    "regularization_parameter = 0.1\n",
    "ranks = [4, 8, 12]\n",
    "errors = [0, 0, 0]\n",
    "err = 0\n",
    "tolerance = 0.02\n",
    "\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "best_iteration = -1\n",
    "for rank in ranks:\n",
    "    model = ALS.train(pre_train_RDD, rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularization_parameter)\n",
    "    predictions = model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    rates_and_preds = pre_valid_RDD.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "    MAE = rates_and_preds.map(lambda r: abs(r[1][0] - r[1][1])).mean()\n",
    "    RMSE = np.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    errors[err] = RMSE\n",
    "    err += 1\n",
    "    print('For rank', rank,'the MAE is: ', MAE,'the RMSE is: ', RMSE) \n",
    "    if RMSE < min_error:\n",
    "        min_error = RMSE\n",
    "        best_rank = rank\n",
    "\n",
    "print('The best model was trained with rank: ', best_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the MAR is 0.6751796857448238\n",
      "For testing data the RMSE is 0.8802398422205924\n"
     ]
    }
   ],
   "source": [
    "model = ALS.train(training_RDD, best_rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularization_parameter)\n",
    "predictions = model.predictAll(test_user_unwatch).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_preds = test_RDD.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "MAE = rates_and_preds.map(lambda r: abs(r[1][0] - r[1][1])).mean()\n",
    "RMSE = np.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "\n",
    "print('For testing data the MAR is', MAE)\n",
    "print('For testing data the RMSE is', RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Top-10 Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#At first, we need to build a list of (user, movie(not watched before))\n",
    "#we first get (user, list(watched movie))\n",
    "user_watched = training_RDD.map(lambda x: (x[0],x[1])).groupByKey()\\\n",
    ".map(lambda x: (x[0], set(x[1])))\n",
    "#get a movie set for function:\n",
    "movie_set = set(small_movies_data.map(lambda x: x[0]).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list((int user, int unwatched)) getUnwatched(int user, set movies):\n",
    "def getUnwatched(user, movies):\n",
    "    unwat_mov = list(movie_set - movies)\n",
    "    unwat_user = [(user, x) for x in unwat_mov]\n",
    "    return unwat_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_unWatched = user_watched.flatMap(lambda x: getUnwatched(x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_recommendations = model.predictAll(user_unWatched).map(lambda r: ((r[0], r[1]), r[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((312, 81132), 3.594017154327881),\n",
       " ((96, 81132), 3.244278589910458),\n",
       " ((600, 81132), 3.1654283745497827),\n",
       " ((324, 81132), 3.3527077471031346),\n",
       " ((180, 81132), 2.8364072517403205),\n",
       " ((156, 81132), 3.240139905189947),\n",
       " ((216, 81132), 3.2890586614329282),\n",
       " ((408, 81132), 3.599622858828204),\n",
       " ((456, 81132), 4.013056526198035),\n",
       " ((480, 81132), 2.9908068948515423)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_recommendations.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTop_Ten(pairs):\n",
    "    pairs.sort(key =lambda x: x[1], reverse = True)\n",
    "    return set([x[0] for x in pairs[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top_Ten = total_recommendations.map(lambda line: (line[0][0], (line[0][1], line[1]))).groupByKey()\\\n",
    ".map(lambda line: (line[0], list(line[1]))).map(lambda line: (line[0], getTop_Ten(line[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(312, {3379, 3567, 4642, 6818, 7815, 8477, 25771, 40491, 58301, 99764}),\n",
       " (96, {720, 3404, 3566, 3925, 5607, 7842, 58303, 59018, 60943, 94070}),\n",
       " (600, {3379, 3567, 5222, 6818, 7815, 40491, 58301, 96004, 99764, 141718}),\n",
       " (324, {1194, 3567, 3846, 4634, 7025, 25947, 26258, 26326, 82378, 141718}),\n",
       " (180, {3925, 4495, 4617, 6201, 7841, 8235, 51931, 59018, 60943, 112804}),\n",
       " (156, {3379, 4495, 6201, 7564, 7815, 7841, 8235, 26326, 58301, 89904}),\n",
       " (216, {3096, 3379, 4495, 4642, 6201, 7564, 7815, 7841, 8235, 89904}),\n",
       " (408, {3567, 3925, 5867, 7815, 7842, 33649, 59018, 60943, 67618, 130518}),\n",
       " (456, {40, 3379, 3567, 3837, 5222, 5480, 33649, 86347, 98279, 130518}),\n",
       " (480, {2239, 4495, 6201, 7815, 7841, 8235, 51931, 59018, 60943, 89904})]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_Ten.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortTest(pairs):\n",
    "    pairs.sort(key = lambda x: x[1], reverse = True)\n",
    "    return [x[0] for x in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlist = test_RDD.map(lambda r: (r[0], (r[1], r[2]))).groupByKey()\\\n",
    ".map(lambda r: (r[0], list(r[1]))).map(lambda line: (line[0], sortTest(line[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, [60756, 68157, 3578, 86345, 71535])]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testlist.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_com = testlist.map(lambda line: (line[0], set(line[1]))).join(Top_Ten)\\\n",
    ".map(lambda x: (len(x[1][0] & x[1][1]), len(x[1][1]),len(x[1][0])))\\\n",
    ".map(lambda x: (x[0]/x[1], x[0]/x[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.0013157894736842107\n",
      "recall:  0.00021420595911864591\n"
     ]
    }
   ],
   "source": [
    "precision = comparison_com.map(lambda x: x[0]).mean()\n",
    "recall = comparison_com.map(lambda x: x[1]).mean()\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_measure:  0.0003684324020398062\n"
     ]
    }
   ],
   "source": [
    "F_measure = 2 * precision *recall/ (precision + recall)\n",
    "print(\"F_measure: \", F_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nDCG(test, prediction):\n",
    "    DCG =0\n",
    "    IDCG = 0\n",
    "    j=1\n",
    "    for i in range(len(test)):\n",
    "        if test[i] in prediction:\n",
    "            DCG+=1/np.log2(1+i+1)\n",
    "            IDCG+=1/np.log2(j+1)\n",
    "            j+=1\n",
    "    if IDCG!=0:\n",
    "        return DCG/IDCG\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_ndcg = testlist.join(Top_Ten).map(lambda x: (x[0] ,nDCG(x[1][0], x[1][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(448, 0.15773243839286438),\n",
       " (606, 0.16730017881017412),\n",
       " (610, 0.13480990596580797),\n",
       " (541, 0.43067655807339306),\n",
       " (305, 0.1781035935540111),\n",
       " (474, 0.125),\n",
       " (41, 0.1810425967800402),\n",
       " (391, 0.17542506358195453)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_ndcg.filter(lambda x: x[1]!=0).take(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
